{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp313-cp313-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\alberto romero\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (6.31.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (75.8.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\alberto romero\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.0.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.76.0-cp313-cp313-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\alberto romero\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (2.3.5)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\alberto romero\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.20.0-cp313-cp313-win_amd64.whl (332.0 MB)\n",
      "Using cached grpcio-1.76.0-cp313-cp313-win_amd64.whl (4.7 MB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: markdown, grpcio, google_pasta, gast, astunparse, tensorboard, tensorflow\n",
      "\n",
      "   ---------------------------------------- 0/7 [markdown]\n",
      "   ---------------------------------------- 0/7 [markdown]\n",
      "   ---------------------------------------- 0/7 [markdown]\n",
      "   ---------------------------------------- 0/7 [markdown]\n",
      "   ---------------------------------------- 0/7 [markdown]\n",
      "   ----- ---------------------------------- 1/7 [grpcio]\n",
      "   ----- ---------------------------------- 1/7 [grpcio]\n",
      "   ----- ---------------------------------- 1/7 [grpcio]\n",
      "   ----- ---------------------------------- 1/7 [grpcio]\n",
      "   ----- ---------------------------------- 1/7 [grpcio]\n",
      "   ----- ---------------------------------- 1/7 [grpcio]\n",
      "   ----------- ---------------------------- 2/7 [google_pasta]\n",
      "   ----------- ---------------------------- 2/7 [google_pasta]\n",
      "   ----------- ---------------------------- 2/7 [google_pasta]\n",
      "   ----------------- ---------------------- 3/7 [gast]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------- ----------- 5/7 [tensorboard]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------- ----- 6/7 [tensorflow]\n",
      "   ---------------------------------------- 7/7 [tensorflow]\n",
      "\n",
      "Successfully installed astunparse-1.6.3 gast-0.6.0 google_pasta-0.2.0 grpcio-1.76.0 markdown-3.10 tensorboard-2.20.0 tensorflow-2.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (25.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 34.8 MB/s  0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.2\n",
      "    Uninstalling pip-25.2:\n",
      "      Successfully uninstalled pip-25.2\n",
      "Successfully installed pip-25.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.2)\n",
      "Collecting keras\n",
      "  Using cached keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\alberto romero\\appdata\\roaming\\python\\python313\\site-packages (from keras) (2.3.5)\n",
      "Requirement already satisfied: rich in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras) (0.0.9)\n",
      "Requirement already satisfied: h5py in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras) (3.13.0)\n",
      "Requirement already satisfied: optree in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras) (0.15.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\alberto romero\\appdata\\roaming\\python\\python313\\site-packages (from keras) (25.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\alberto romero\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\alberto romero\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Using cached keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.9.2\n",
      "    Uninstalling keras-3.9.2:\n",
      "      Successfully uninstalled keras-3.9.2\n",
      "Successfully installed keras-3.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install keras --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf<6,>=5.28.3\n",
      "  Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Using cached protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 6.31.1\n",
      "    Uninstalling protobuf-6.31.1:\n",
      "      Successfully uninstalled protobuf-6.31.1\n",
      "Successfully installed protobuf-5.29.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Alberto Romero\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\~upb'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"protobuf>=5.28.3,<6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en la siguiente versión dicen que no hará falta usar protobuf menor de la versión 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('Greys'));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint8(255)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.13066047)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "#model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "model.add(keras.layers.Input(shape=((28, 28))))\n",
    "\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    #keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Input(shape=(28, 28)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Flatten name=flatten, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06523715,  0.06323341, -0.07353044, ...,  0.02270768,\n",
       "         0.04254903, -0.04223346],\n",
       "       [ 0.00750845,  0.01635586, -0.01565421, ...,  0.01935138,\n",
       "        -0.01155591, -0.06909249],\n",
       "       [-0.01583084,  0.04369369,  0.0243899 , ...,  0.0704425 ,\n",
       "         0.00028973,  0.0379807 ],\n",
       "       ...,\n",
       "       [-0.00586426, -0.05841251,  0.05182852, ..., -0.00143751,\n",
       "        -0.02719956,  0.02987447],\n",
       "       [-0.05304849, -0.04382157, -0.05149212, ..., -0.04508246,\n",
       "         0.04587834, -0.00014073],\n",
       "       [ 0.04766268, -0.05680361,  0.04042324, ...,  0.01907958,\n",
       "        -0.00138703,  0.04957102]], shape=(784, 300), dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784 * 300 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235500\n"
     ]
    }
   ],
   "source": [
    "# 1º neurona de la 1º hidden layer\n",
    "# y = a + w1*x1 + w2*x2 + .... wn*xn\n",
    "# a es el intercepto llamado bias\n",
    "# wn es cada uno de los pesos que va a ir actualizando con el backpropagation\n",
    "# n es 784\n",
    "# En la 1º hidden layer tenemos 784 pesos por cada neurona, al tener 300, tenemos un total de:\n",
    "print(784*300 + 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 784 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30100"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 100 + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * 10 + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6876 - loss: 1.2966 - val_accuracy: 0.8566 - val_loss: 0.6200\n",
      "Epoch 2/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8631 - loss: 0.5291 - val_accuracy: 0.8913 - val_loss: 0.4063\n",
      "Epoch 3/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8883 - loss: 0.4044 - val_accuracy: 0.9058 - val_loss: 0.3401\n",
      "Epoch 4/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9016 - loss: 0.3517 - val_accuracy: 0.9133 - val_loss: 0.3069\n",
      "Epoch 5/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 0.3201 - val_accuracy: 0.9201 - val_loss: 0.2852\n",
      "Epoch 6/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2976 - val_accuracy: 0.9244 - val_loss: 0.2676\n",
      "Epoch 7/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9208 - loss: 0.2796 - val_accuracy: 0.9273 - val_loss: 0.2544\n",
      "Epoch 8/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9248 - loss: 0.2650 - val_accuracy: 0.9316 - val_loss: 0.2434\n",
      "Epoch 9/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9281 - loss: 0.2522 - val_accuracy: 0.9354 - val_loss: 0.2311\n",
      "Epoch 10/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9315 - loss: 0.2408 - val_accuracy: 0.9383 - val_loss: 0.2236\n",
      "Epoch 11/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.2308 - val_accuracy: 0.9392 - val_loss: 0.2150\n",
      "Epoch 12/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.2217 - val_accuracy: 0.9423 - val_loss: 0.2092\n",
      "Epoch 13/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9395 - loss: 0.2132 - val_accuracy: 0.9454 - val_loss: 0.2008\n",
      "Epoch 14/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9416 - loss: 0.2054 - val_accuracy: 0.9473 - val_loss: 0.1944\n",
      "Epoch 15/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9436 - loss: 0.1983 - val_accuracy: 0.9498 - val_loss: 0.1876\n",
      "Epoch 16/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9457 - loss: 0.1913 - val_accuracy: 0.9497 - val_loss: 0.1836\n",
      "Epoch 17/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.1849 - val_accuracy: 0.9518 - val_loss: 0.1802\n",
      "Epoch 18/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9490 - loss: 0.1793 - val_accuracy: 0.9540 - val_loss: 0.1743\n",
      "Epoch 19/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9507 - loss: 0.1734 - val_accuracy: 0.9546 - val_loss: 0.1704\n",
      "Epoch 20/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.1683 - val_accuracy: 0.9554 - val_loss: 0.1649\n",
      "Epoch 21/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9533 - loss: 0.1633 - val_accuracy: 0.9547 - val_loss: 0.1620\n",
      "Epoch 22/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.1586 - val_accuracy: 0.9571 - val_loss: 0.1571\n",
      "Epoch 23/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9556 - loss: 0.1540 - val_accuracy: 0.9570 - val_loss: 0.1539\n",
      "Epoch 24/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1497 - val_accuracy: 0.9592 - val_loss: 0.1510\n",
      "Epoch 25/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9584 - loss: 0.1457 - val_accuracy: 0.9598 - val_loss: 0.1484\n",
      "Epoch 26/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1417 - val_accuracy: 0.9604 - val_loss: 0.1444\n",
      "Epoch 27/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1379 - val_accuracy: 0.9619 - val_loss: 0.1424\n",
      "Epoch 28/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.1344 - val_accuracy: 0.9619 - val_loss: 0.1397\n",
      "Epoch 29/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.1310 - val_accuracy: 0.9636 - val_loss: 0.1377\n",
      "Epoch 30/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.1278 - val_accuracy: 0.9633 - val_loss: 0.1351\n",
      "Epoch 31/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.1246 - val_accuracy: 0.9641 - val_loss: 0.1320\n",
      "Epoch 32/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.1215 - val_accuracy: 0.9645 - val_loss: 0.1316\n",
      "Epoch 33/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.1187 - val_accuracy: 0.9655 - val_loss: 0.1291\n",
      "Epoch 34/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9681 - loss: 0.1157 - val_accuracy: 0.9659 - val_loss: 0.1264\n",
      "Epoch 35/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.1134 - val_accuracy: 0.9656 - val_loss: 0.1246\n",
      "Epoch 36/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9690 - loss: 0.1106 - val_accuracy: 0.9662 - val_loss: 0.1239\n",
      "Epoch 37/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9706 - loss: 0.1081 - val_accuracy: 0.9660 - val_loss: 0.1235\n",
      "Epoch 38/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9711 - loss: 0.1057 - val_accuracy: 0.9674 - val_loss: 0.1190\n",
      "Epoch 39/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9715 - loss: 0.1035 - val_accuracy: 0.9674 - val_loss: 0.1182\n",
      "Epoch 40/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9722 - loss: 0.1012 - val_accuracy: 0.9676 - val_loss: 0.1157\n",
      "Epoch 41/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9730 - loss: 0.0991 - val_accuracy: 0.9682 - val_loss: 0.1154\n",
      "Epoch 42/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9735 - loss: 0.0969 - val_accuracy: 0.9687 - val_loss: 0.1139\n",
      "Epoch 43/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9739 - loss: 0.0949 - val_accuracy: 0.9695 - val_loss: 0.1121\n",
      "Epoch 44/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9745 - loss: 0.0929 - val_accuracy: 0.9689 - val_loss: 0.1117\n",
      "Epoch 45/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9754 - loss: 0.0910 - val_accuracy: 0.9696 - val_loss: 0.1102\n",
      "Epoch 46/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.0892 - val_accuracy: 0.9700 - val_loss: 0.1082\n",
      "Epoch 47/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.0874 - val_accuracy: 0.9701 - val_loss: 0.1094\n",
      "Epoch 48/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.0856 - val_accuracy: 0.9711 - val_loss: 0.1069\n",
      "Epoch 49/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.0840 - val_accuracy: 0.9709 - val_loss: 0.1068\n",
      "Epoch 50/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.0824 - val_accuracy: 0.9714 - val_loss: 0.1043\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9776 - loss: 0.0817 - val_accuracy: 0.9723 - val_loss: 0.1016\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9789 - loss: 0.0790 - val_accuracy: 0.9713 - val_loss: 0.1037\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 0.0758 - val_accuracy: 0.9721 - val_loss: 0.0997\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0734 - val_accuracy: 0.9730 - val_loss: 0.0974\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9805 - loss: 0.0709 - val_accuracy: 0.9728 - val_loss: 0.0981\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0682 - val_accuracy: 0.9733 - val_loss: 0.0960\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.0658 - val_accuracy: 0.9740 - val_loss: 0.0933\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0638 - val_accuracy: 0.9741 - val_loss: 0.0924\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0618 - val_accuracy: 0.9736 - val_loss: 0.0919\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0595 - val_accuracy: 0.9745 - val_loss: 0.0908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f186c71450>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': [0.6876000165939331, 0.8630599975585938, 0.8883200287818909, 0.9015600085258484, 0.9099599719047546, 0.9155799746513367, 0.9207599759101868, 0.924780011177063, 0.9281399846076965, 0.9315400123596191, 0.9345399737358093, 0.9373999834060669, 0.9395400285720825, 0.9416400194168091, 0.943560004234314, 0.9456800222396851, 0.9468200206756592, 0.9490000009536743, 0.9506999850273132, 0.952019989490509, 0.953279972076416, 0.9545800089836121, 0.9556199908256531, 0.9570599794387817, 0.9584199786186218, 0.9592999815940857, 0.9604399800300598, 0.9614800214767456, 0.9626799821853638, 0.9638000130653381, 0.9653199911117554, 0.9656800031661987, 0.9667199850082397, 0.9681400060653687, 0.968280017375946, 0.968999981880188, 0.970579981803894, 0.9711199998855591, 0.9715200066566467, 0.9722200036048889, 0.9729599952697754, 0.9735199809074402, 0.9739199876785278, 0.9745399951934814, 0.9753999710083008, 0.9755600094795227, 0.9763000011444092, 0.9763399958610535, 0.9769600033760071, 0.9776399731636047], 'loss': [1.2966355085372925, 0.529087245464325, 0.40442606806755066, 0.35165342688560486, 0.3201349973678589, 0.2975962460041046, 0.2796172797679901, 0.26499223709106445, 0.25220224261283875, 0.2408129721879959, 0.23078270256519318, 0.22170400619506836, 0.2132248431444168, 0.20540203154087067, 0.19831712543964386, 0.19129963219165802, 0.18491718173027039, 0.1792607605457306, 0.17344917356967926, 0.16827040910720825, 0.16329200565814972, 0.15855969488620758, 0.1539837270975113, 0.14969559013843536, 0.1456717997789383, 0.14169228076934814, 0.13785268366336823, 0.13439609110355377, 0.1310064196586609, 0.12781202793121338, 0.12459993362426758, 0.12151487171649933, 0.11868444085121155, 0.1157224029302597, 0.11339396238327026, 0.11060088872909546, 0.10813843458890915, 0.10573165863752365, 0.10346903651952744, 0.10117315500974655, 0.09909501671791077, 0.0969008281826973, 0.09494727849960327, 0.09291897714138031, 0.09104590862989426, 0.08918798714876175, 0.08735913783311844, 0.08563995361328125, 0.08396274596452713, 0.08239271491765976], 'val_accuracy': [0.8565999865531921, 0.8913000226020813, 0.9057999849319458, 0.9132999777793884, 0.9200999736785889, 0.9243999719619751, 0.927299976348877, 0.9315999746322632, 0.9354000091552734, 0.9383000135421753, 0.9391999840736389, 0.942300021648407, 0.9453999996185303, 0.9473000168800354, 0.9498000144958496, 0.9496999979019165, 0.9517999887466431, 0.9539999961853027, 0.9545999765396118, 0.9553999900817871, 0.9546999931335449, 0.957099974155426, 0.9570000171661377, 0.9592000246047974, 0.9598000049591064, 0.9603999853134155, 0.961899995803833, 0.961899995803833, 0.9635999798774719, 0.9632999897003174, 0.9641000032424927, 0.9645000100135803, 0.965499997138977, 0.9659000039100647, 0.9656000137329102, 0.9661999940872192, 0.9660000205039978, 0.9674000144004822, 0.9674000144004822, 0.9675999879837036, 0.9682000279426575, 0.9686999917030334, 0.9695000052452087, 0.9689000248908997, 0.9696000218391418, 0.9700000286102295, 0.9700999855995178, 0.9710999727249146, 0.9708999991416931, 0.9714000225067139], 'val_loss': [0.6200433969497681, 0.40625786781311035, 0.34010154008865356, 0.30688589811325073, 0.2852058708667755, 0.2676086723804474, 0.25437283515930176, 0.24336589872837067, 0.231149360537529, 0.22358746826648712, 0.21502651274204254, 0.20923393964767456, 0.20082561671733856, 0.19439761340618134, 0.18760767579078674, 0.1835591048002243, 0.1801944524049759, 0.174317866563797, 0.17037373781204224, 0.164906308054924, 0.1620461493730545, 0.15705907344818115, 0.1539023369550705, 0.1510307639837265, 0.14842283725738525, 0.14437374472618103, 0.142360121011734, 0.13967709243297577, 0.1377076506614685, 0.13506223261356354, 0.1319788694381714, 0.13163524866104126, 0.12913373112678528, 0.12638230621814728, 0.12462509423494339, 0.12387004494667053, 0.12351756542921066, 0.1189705953001976, 0.11821019649505615, 0.11571978777647018, 0.11540533602237701, 0.11391162127256393, 0.1120663732290268, 0.11172492802143097, 0.11021275818347931, 0.10818928480148315, 0.10939896106719971, 0.1068601906299591, 0.10675119608640671, 0.10429650545120239]}\n"
     ]
    }
   ],
   "source": [
    "# print(history.params)\n",
    "# print(history.epoch)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.6876000165939331,\n",
       "  0.8630599975585938,\n",
       "  0.8883200287818909,\n",
       "  0.9015600085258484,\n",
       "  0.9099599719047546,\n",
       "  0.9155799746513367,\n",
       "  0.9207599759101868,\n",
       "  0.924780011177063,\n",
       "  0.9281399846076965,\n",
       "  0.9315400123596191,\n",
       "  0.9345399737358093,\n",
       "  0.9373999834060669,\n",
       "  0.9395400285720825,\n",
       "  0.9416400194168091,\n",
       "  0.943560004234314,\n",
       "  0.9456800222396851,\n",
       "  0.9468200206756592,\n",
       "  0.9490000009536743,\n",
       "  0.9506999850273132,\n",
       "  0.952019989490509,\n",
       "  0.953279972076416,\n",
       "  0.9545800089836121,\n",
       "  0.9556199908256531,\n",
       "  0.9570599794387817,\n",
       "  0.9584199786186218,\n",
       "  0.9592999815940857,\n",
       "  0.9604399800300598,\n",
       "  0.9614800214767456,\n",
       "  0.9626799821853638,\n",
       "  0.9638000130653381,\n",
       "  0.9653199911117554,\n",
       "  0.9656800031661987,\n",
       "  0.9667199850082397,\n",
       "  0.9681400060653687,\n",
       "  0.968280017375946,\n",
       "  0.968999981880188,\n",
       "  0.970579981803894,\n",
       "  0.9711199998855591,\n",
       "  0.9715200066566467,\n",
       "  0.9722200036048889,\n",
       "  0.9729599952697754,\n",
       "  0.9735199809074402,\n",
       "  0.9739199876785278,\n",
       "  0.9745399951934814,\n",
       "  0.9753999710083008,\n",
       "  0.9755600094795227,\n",
       "  0.9763000011444092,\n",
       "  0.9763399958610535,\n",
       "  0.9769600033760071,\n",
       "  0.9776399731636047],\n",
       " 'loss': [1.2966355085372925,\n",
       "  0.529087245464325,\n",
       "  0.40442606806755066,\n",
       "  0.35165342688560486,\n",
       "  0.3201349973678589,\n",
       "  0.2975962460041046,\n",
       "  0.2796172797679901,\n",
       "  0.26499223709106445,\n",
       "  0.25220224261283875,\n",
       "  0.2408129721879959,\n",
       "  0.23078270256519318,\n",
       "  0.22170400619506836,\n",
       "  0.2132248431444168,\n",
       "  0.20540203154087067,\n",
       "  0.19831712543964386,\n",
       "  0.19129963219165802,\n",
       "  0.18491718173027039,\n",
       "  0.1792607605457306,\n",
       "  0.17344917356967926,\n",
       "  0.16827040910720825,\n",
       "  0.16329200565814972,\n",
       "  0.15855969488620758,\n",
       "  0.1539837270975113,\n",
       "  0.14969559013843536,\n",
       "  0.1456717997789383,\n",
       "  0.14169228076934814,\n",
       "  0.13785268366336823,\n",
       "  0.13439609110355377,\n",
       "  0.1310064196586609,\n",
       "  0.12781202793121338,\n",
       "  0.12459993362426758,\n",
       "  0.12151487171649933,\n",
       "  0.11868444085121155,\n",
       "  0.1157224029302597,\n",
       "  0.11339396238327026,\n",
       "  0.11060088872909546,\n",
       "  0.10813843458890915,\n",
       "  0.10573165863752365,\n",
       "  0.10346903651952744,\n",
       "  0.10117315500974655,\n",
       "  0.09909501671791077,\n",
       "  0.0969008281826973,\n",
       "  0.09494727849960327,\n",
       "  0.09291897714138031,\n",
       "  0.09104590862989426,\n",
       "  0.08918798714876175,\n",
       "  0.08735913783311844,\n",
       "  0.08563995361328125,\n",
       "  0.08396274596452713,\n",
       "  0.08239271491765976],\n",
       " 'val_accuracy': [0.8565999865531921,\n",
       "  0.8913000226020813,\n",
       "  0.9057999849319458,\n",
       "  0.9132999777793884,\n",
       "  0.9200999736785889,\n",
       "  0.9243999719619751,\n",
       "  0.927299976348877,\n",
       "  0.9315999746322632,\n",
       "  0.9354000091552734,\n",
       "  0.9383000135421753,\n",
       "  0.9391999840736389,\n",
       "  0.942300021648407,\n",
       "  0.9453999996185303,\n",
       "  0.9473000168800354,\n",
       "  0.9498000144958496,\n",
       "  0.9496999979019165,\n",
       "  0.9517999887466431,\n",
       "  0.9539999961853027,\n",
       "  0.9545999765396118,\n",
       "  0.9553999900817871,\n",
       "  0.9546999931335449,\n",
       "  0.957099974155426,\n",
       "  0.9570000171661377,\n",
       "  0.9592000246047974,\n",
       "  0.9598000049591064,\n",
       "  0.9603999853134155,\n",
       "  0.961899995803833,\n",
       "  0.961899995803833,\n",
       "  0.9635999798774719,\n",
       "  0.9632999897003174,\n",
       "  0.9641000032424927,\n",
       "  0.9645000100135803,\n",
       "  0.965499997138977,\n",
       "  0.9659000039100647,\n",
       "  0.9656000137329102,\n",
       "  0.9661999940872192,\n",
       "  0.9660000205039978,\n",
       "  0.9674000144004822,\n",
       "  0.9674000144004822,\n",
       "  0.9675999879837036,\n",
       "  0.9682000279426575,\n",
       "  0.9686999917030334,\n",
       "  0.9695000052452087,\n",
       "  0.9689000248908997,\n",
       "  0.9696000218391418,\n",
       "  0.9700000286102295,\n",
       "  0.9700999855995178,\n",
       "  0.9710999727249146,\n",
       "  0.9708999991416931,\n",
       "  0.9714000225067139],\n",
       " 'val_loss': [0.6200433969497681,\n",
       "  0.40625786781311035,\n",
       "  0.34010154008865356,\n",
       "  0.30688589811325073,\n",
       "  0.2852058708667755,\n",
       "  0.2676086723804474,\n",
       "  0.25437283515930176,\n",
       "  0.24336589872837067,\n",
       "  0.231149360537529,\n",
       "  0.22358746826648712,\n",
       "  0.21502651274204254,\n",
       "  0.20923393964767456,\n",
       "  0.20082561671733856,\n",
       "  0.19439761340618134,\n",
       "  0.18760767579078674,\n",
       "  0.1835591048002243,\n",
       "  0.1801944524049759,\n",
       "  0.174317866563797,\n",
       "  0.17037373781204224,\n",
       "  0.164906308054924,\n",
       "  0.1620461493730545,\n",
       "  0.15705907344818115,\n",
       "  0.1539023369550705,\n",
       "  0.1510307639837265,\n",
       "  0.14842283725738525,\n",
       "  0.14437374472618103,\n",
       "  0.142360121011734,\n",
       "  0.13967709243297577,\n",
       "  0.1377076506614685,\n",
       "  0.13506223261356354,\n",
       "  0.1319788694381714,\n",
       "  0.13163524866104126,\n",
       "  0.12913373112678528,\n",
       "  0.12638230621814728,\n",
       "  0.12462509423494339,\n",
       "  0.12387004494667053,\n",
       "  0.12351756542921066,\n",
       "  0.1189705953001976,\n",
       "  0.11821019649505615,\n",
       "  0.11571978777647018,\n",
       "  0.11540533602237701,\n",
       "  0.11391162127256393,\n",
       "  0.1120663732290268,\n",
       "  0.11172492802143097,\n",
       "  0.11021275818347931,\n",
       "  0.10818928480148315,\n",
       "  0.10939896106719971,\n",
       "  0.1068601906299591,\n",
       "  0.10675119608640671,\n",
       "  0.10429650545120239]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.68760</td>\n",
       "      <td>1.296636</td>\n",
       "      <td>0.8566</td>\n",
       "      <td>0.620043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.86306</td>\n",
       "      <td>0.529087</td>\n",
       "      <td>0.8913</td>\n",
       "      <td>0.406258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.88832</td>\n",
       "      <td>0.404426</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>0.340102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.90156</td>\n",
       "      <td>0.351653</td>\n",
       "      <td>0.9133</td>\n",
       "      <td>0.306886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90996</td>\n",
       "      <td>0.320135</td>\n",
       "      <td>0.9201</td>\n",
       "      <td>0.285206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.91558</td>\n",
       "      <td>0.297596</td>\n",
       "      <td>0.9244</td>\n",
       "      <td>0.267609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.92076</td>\n",
       "      <td>0.279617</td>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.254373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.92478</td>\n",
       "      <td>0.264992</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>0.243366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.92814</td>\n",
       "      <td>0.252202</td>\n",
       "      <td>0.9354</td>\n",
       "      <td>0.231149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.93154</td>\n",
       "      <td>0.240813</td>\n",
       "      <td>0.9383</td>\n",
       "      <td>0.223587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.93454</td>\n",
       "      <td>0.230783</td>\n",
       "      <td>0.9392</td>\n",
       "      <td>0.215027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.93740</td>\n",
       "      <td>0.221704</td>\n",
       "      <td>0.9423</td>\n",
       "      <td>0.209234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.93954</td>\n",
       "      <td>0.213225</td>\n",
       "      <td>0.9454</td>\n",
       "      <td>0.200826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.94164</td>\n",
       "      <td>0.205402</td>\n",
       "      <td>0.9473</td>\n",
       "      <td>0.194398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.94356</td>\n",
       "      <td>0.198317</td>\n",
       "      <td>0.9498</td>\n",
       "      <td>0.187608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.94568</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.9497</td>\n",
       "      <td>0.183559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.94682</td>\n",
       "      <td>0.184917</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.180194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.94900</td>\n",
       "      <td>0.179261</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.174318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.95070</td>\n",
       "      <td>0.173449</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>0.170374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.95202</td>\n",
       "      <td>0.168270</td>\n",
       "      <td>0.9554</td>\n",
       "      <td>0.164906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.95328</td>\n",
       "      <td>0.163292</td>\n",
       "      <td>0.9547</td>\n",
       "      <td>0.162046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.95458</td>\n",
       "      <td>0.158560</td>\n",
       "      <td>0.9571</td>\n",
       "      <td>0.157059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.95562</td>\n",
       "      <td>0.153984</td>\n",
       "      <td>0.9570</td>\n",
       "      <td>0.153902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.95706</td>\n",
       "      <td>0.149696</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.151031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.95842</td>\n",
       "      <td>0.145672</td>\n",
       "      <td>0.9598</td>\n",
       "      <td>0.148423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.95930</td>\n",
       "      <td>0.141692</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.144374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.96044</td>\n",
       "      <td>0.137853</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>0.142360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.96148</td>\n",
       "      <td>0.134396</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>0.139677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.96268</td>\n",
       "      <td>0.131006</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>0.137708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.96380</td>\n",
       "      <td>0.127812</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.135062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.96532</td>\n",
       "      <td>0.124600</td>\n",
       "      <td>0.9641</td>\n",
       "      <td>0.131979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.96568</td>\n",
       "      <td>0.121515</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>0.131635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.96672</td>\n",
       "      <td>0.118684</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>0.129134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.96814</td>\n",
       "      <td>0.115722</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>0.126382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.96828</td>\n",
       "      <td>0.113394</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>0.124625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.96900</td>\n",
       "      <td>0.110601</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.123870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.97058</td>\n",
       "      <td>0.108138</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.123518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.97112</td>\n",
       "      <td>0.105732</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.118971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.97152</td>\n",
       "      <td>0.103469</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.118210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.97222</td>\n",
       "      <td>0.101173</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.115720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.97296</td>\n",
       "      <td>0.099095</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.115405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.97352</td>\n",
       "      <td>0.096901</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.113912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.97392</td>\n",
       "      <td>0.094947</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>0.112066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.97454</td>\n",
       "      <td>0.092919</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.111725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.97540</td>\n",
       "      <td>0.091046</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.110213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.97556</td>\n",
       "      <td>0.089188</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.108189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.97630</td>\n",
       "      <td>0.087359</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>0.109399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.97634</td>\n",
       "      <td>0.085640</td>\n",
       "      <td>0.9711</td>\n",
       "      <td>0.106860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.97696</td>\n",
       "      <td>0.083963</td>\n",
       "      <td>0.9709</td>\n",
       "      <td>0.106751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.97764</td>\n",
       "      <td>0.082393</td>\n",
       "      <td>0.9714</td>\n",
       "      <td>0.104297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy      loss  val_accuracy  val_loss\n",
       "0    0.68760  1.296636        0.8566  0.620043\n",
       "1    0.86306  0.529087        0.8913  0.406258\n",
       "2    0.88832  0.404426        0.9058  0.340102\n",
       "3    0.90156  0.351653        0.9133  0.306886\n",
       "4    0.90996  0.320135        0.9201  0.285206\n",
       "5    0.91558  0.297596        0.9244  0.267609\n",
       "6    0.92076  0.279617        0.9273  0.254373\n",
       "7    0.92478  0.264992        0.9316  0.243366\n",
       "8    0.92814  0.252202        0.9354  0.231149\n",
       "9    0.93154  0.240813        0.9383  0.223587\n",
       "10   0.93454  0.230783        0.9392  0.215027\n",
       "11   0.93740  0.221704        0.9423  0.209234\n",
       "12   0.93954  0.213225        0.9454  0.200826\n",
       "13   0.94164  0.205402        0.9473  0.194398\n",
       "14   0.94356  0.198317        0.9498  0.187608\n",
       "15   0.94568  0.191300        0.9497  0.183559\n",
       "16   0.94682  0.184917        0.9518  0.180194\n",
       "17   0.94900  0.179261        0.9540  0.174318\n",
       "18   0.95070  0.173449        0.9546  0.170374\n",
       "19   0.95202  0.168270        0.9554  0.164906\n",
       "20   0.95328  0.163292        0.9547  0.162046\n",
       "21   0.95458  0.158560        0.9571  0.157059\n",
       "22   0.95562  0.153984        0.9570  0.153902\n",
       "23   0.95706  0.149696        0.9592  0.151031\n",
       "24   0.95842  0.145672        0.9598  0.148423\n",
       "25   0.95930  0.141692        0.9604  0.144374\n",
       "26   0.96044  0.137853        0.9619  0.142360\n",
       "27   0.96148  0.134396        0.9619  0.139677\n",
       "28   0.96268  0.131006        0.9636  0.137708\n",
       "29   0.96380  0.127812        0.9633  0.135062\n",
       "30   0.96532  0.124600        0.9641  0.131979\n",
       "31   0.96568  0.121515        0.9645  0.131635\n",
       "32   0.96672  0.118684        0.9655  0.129134\n",
       "33   0.96814  0.115722        0.9659  0.126382\n",
       "34   0.96828  0.113394        0.9656  0.124625\n",
       "35   0.96900  0.110601        0.9662  0.123870\n",
       "36   0.97058  0.108138        0.9660  0.123518\n",
       "37   0.97112  0.105732        0.9674  0.118971\n",
       "38   0.97152  0.103469        0.9674  0.118210\n",
       "39   0.97222  0.101173        0.9676  0.115720\n",
       "40   0.97296  0.099095        0.9682  0.115405\n",
       "41   0.97352  0.096901        0.9687  0.113912\n",
       "42   0.97392  0.094947        0.9695  0.112066\n",
       "43   0.97454  0.092919        0.9689  0.111725\n",
       "44   0.97540  0.091046        0.9696  0.110213\n",
       "45   0.97556  0.089188        0.9700  0.108189\n",
       "46   0.97630  0.087359        0.9701  0.109399\n",
       "47   0.97634  0.085640        0.9711  0.106860\n",
       "48   0.97696  0.083963        0.9709  0.106751\n",
       "49   0.97764  0.082393        0.9714  0.104297"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9722 - loss: 0.0900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09002555161714554, 0.9721999764442444]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.001, 0.   , 0.   , 0.   , 0.999, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1])\n",
    "print(predictions.shape)\n",
    "np.round(predictions,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(7)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], shape=(10000,))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1].reshape(28,28), cmap=plt.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 969,    0,    0,    1,    1,    2,    3,    1,    2,    1],\n",
       "       [   0, 1121,    3,    1,    0,    2,    4,    0,    4,    0],\n",
       "       [   5,    2, 1010,    2,    1,    0,    2,    5,    5,    0],\n",
       "       [   0,    1,    5,  983,    0,    5,    1,    6,    6,    3],\n",
       "       [   1,    0,    5,    1,  958,    0,    2,    2,    1,   12],\n",
       "       [   6,    1,    0,   10,    3,  851,   10,    1,    6,    4],\n",
       "       [   4,    3,    1,    0,    8,    5,  933,    0,    4,    0],\n",
       "       [   2,   11,   12,    4,    0,    0,    0,  991,    1,    7],\n",
       "       [   5,    0,    1,    8,    3,    4,    7,    4,  939,    3],\n",
       "       [   4,    5,    3,    7,   13,    2,    2,    5,    1,  967]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(y_test, model.predict(X_test).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98       980\n",
      "         1.0       0.98      0.99      0.98      1135\n",
      "         2.0       0.97      0.98      0.97      1032\n",
      "         3.0       0.97      0.97      0.97      1010\n",
      "         4.0       0.97      0.98      0.97       982\n",
      "         5.0       0.98      0.95      0.97       892\n",
      "         6.0       0.97      0.97      0.97       958\n",
      "         7.0       0.98      0.96      0.97      1028\n",
      "         8.0       0.97      0.96      0.97       974\n",
      "         9.0       0.97      0.96      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test).argmax(axis=1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.4252 - val_loss: 0.7452\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5927 - val_loss: 0.4525\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4451 - val_loss: 0.3873\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4212 - val_loss: 0.3776\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4002 - val_loss: 0.3591\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3898 - val_loss: 0.3578\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3851 - val_loss: 0.3501\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3826 - val_loss: 0.3445\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3801 - val_loss: 0.3494\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3768 - val_loss: 0.3451\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3741 - val_loss: 0.3434\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3738 - val_loss: 0.3380\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3700 - val_loss: 0.3355\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3690 - val_loss: 0.3422\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3676 - val_loss: 0.3334\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3653 - val_loss: 0.3300\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3636 - val_loss: 0.3296\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3621 - val_loss: 0.3301\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3655 - val_loss: 0.3350\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3611 - val_loss: 0.3288\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation = 'relu'),\n",
    "                      #input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">303</span> (1.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m303\u001b[0m (1.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3724  \n",
      "0.3723529577255249\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.7556653],\n",
       "       [3.2168756],\n",
       "       [2.2540374],\n",
       "       [1.045425 ],\n",
       "       [1.5827267]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.keras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3822\n",
      "Epoch 2/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3676  \n",
      "Epoch 3/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3583  \n",
      "Epoch 4/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3562  \n",
      "Epoch 5/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4291  \n",
      "Epoch 6/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3589 \n",
      "Epoch 7/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3561\n",
      "Epoch 8/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3539  \n",
      "Epoch 9/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3546\n",
      "Epoch 10/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3505\n",
      "Epoch 11/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3488\n",
      "Epoch 12/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3479\n",
      "Epoch 13/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3472\n",
      "Epoch 14/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3460\n",
      "Epoch 15/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3449\n",
      "Epoch 16/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3437\n",
      "Epoch 17/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3433\n",
      "Epoch 18/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3417\n",
      "Epoch 19/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3402\n",
      "Epoch 20/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3394\n",
      "Epoch 21/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3381\n",
      "Epoch 22/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3378\n",
      "Epoch 23/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3372\n",
      "Epoch 24/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3353\n",
      "Epoch 25/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3342\n",
      "Epoch 26/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3335\n",
      "Epoch 27/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3335\n",
      "Epoch 28/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3326\n",
      "Epoch 29/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3319\n",
      "Epoch 30/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3393\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.keras\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3389 - val_loss: 0.3065\n",
      "Epoch 2/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3325 - val_loss: 0.3078\n",
      "Epoch 3/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3310 - val_loss: 0.3014\n",
      "Epoch 4/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3278 - val_loss: 0.3029\n",
      "Epoch 5/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3295 - val_loss: 0.3081\n",
      "Epoch 6/50\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3275 - val_loss: 0.3168\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=50,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb, checkpoint_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
